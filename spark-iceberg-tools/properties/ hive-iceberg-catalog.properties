# Iceberg Spark session extensions
spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions

# Configure Iceberg to use Hive catalog
spark.sql.catalog.spark_catalog=org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.spark_catalog.type=hive
spark.sql.catalog.spark_catalog.uri=thrift://localhost:9083  # Replace with your Hive Metastore URI

# S3 configuration for the underlying file system if using S3 for data storage
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
# Credentials and configurations specific to your AWS setup might also be needed, such as:
# spark.hadoop.fs.s3a.access.key=<your-access-key>
# spark.hadoop.fs.s3a.secret.key=<your-secret-key>

# Spark driver memory
spark.driver.memory=5g